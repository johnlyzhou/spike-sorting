{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d291d217",
   "metadata": {},
   "source": [
    "## Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Colab (follow instructions at https://github.com/johnlyzhou/spike-sorting for local installation)\n",
    "\n",
    "from google.colab import drive\n",
    "from IPython.display import clear_output \n",
    "\n",
    "# Install packages and requirements\n",
    "!git clone https://github.com/johnlyzhou/spike-sorting.git\n",
    "%cd spike-sorting\n",
    "!pip install -r requirements.txt\n",
    "!pip install -e .\n",
    "clear_output()\n",
    "\n",
    "# Download sample waveform templates\n",
    "!gdown --id 1FY86UUkV-QdPpAMQGzNiU-wN3W9dtPLo -O /content/spike-sorting/data/raw/templates_yass.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7436ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.data.preprocess_templates import (\n",
    "    plot_templates, \n",
    "    get_max_chan_temps, \n",
    "    take_channel_range, \n",
    "    localize_wfs\n",
    ")\n",
    "from src.data.make_datasets import (\n",
    "    featurization_dataset, \n",
    "    positional_invariance_dataset, \n",
    "    clustering_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e966b4",
   "metadata": {
    "id": "25e966b4"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98fdd9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PATH = \"/Users/johnzhou/research/spike-sorting\"\n",
    "RAW_DATA_DIR = Path(f\"{REPO_PATH}/data/raw\")\n",
    "PROCESS_DATA_DIR = Path(f\"{REPO_PATH}/data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dafa560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 templates, 121 timesteps, 384 channels.\n"
     ]
    }
   ],
   "source": [
    "# Cleaned and denoised templates\n",
    "templates_fname = \"templates_yass.npy\"\n",
    "templates_fpath = Path(f\"{RAW_DATA_DIR}/{templates_fname}\")\n",
    "templates = np.load(templates_fpath)\n",
    "num_templates, num_timesteps, num_chans = templates.shape\n",
    "print(f\"{num_templates} templates, {num_timesteps} timesteps, {num_chans} channels.\")\n",
    "\n",
    "# Probe geometry\n",
    "geom_fname = \"channel_map_np2.npy\"\n",
    "geom_fpath = Path(f\"{RAW_DATA_DIR}/{geom_fname}\")\n",
    "geom_array = np.load(geom_fpath)\n",
    "\n",
    "# Raw recordings for noise\n",
    "raw_10s_path = f\"{RAW_DATA_DIR}/ten_np2_seconds.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22b87d3",
   "metadata": {
    "id": "b22b87d3"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9293a6",
   "metadata": {
    "id": "0e9293a6"
   },
   "source": [
    "### Identify and Remove Bad Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6092fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of channels to take around max channel\n",
    "n_channels = 20\n",
    "channel_positions = geom_array[:n_channels]\n",
    "\n",
    "# Look at each template and note which ones are \"bad\", i.e. don't look like typical spikes\n",
    "max_chan_temp = get_max_chan_temps(templates)\n",
    "# plot_templates(templates, max_chan_temp, n_channels=n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ec9541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 good templates remaining.\n"
     ]
    }
   ],
   "source": [
    "# Remove the bad templates by index\n",
    "bad_template_idxs = [3, 6, 27, 29, 32, 35, 36, 56, 57, 58, 59, 62, 63, 64, 74, 78, 79, 80, 85, 91, 92, \\\n",
    "    101, 107, 109, 110, 111, 118, 119, 121, 145, 150, 151, 152, 157, 159, 164, 165, 169]\n",
    "good_templates = np.delete(templates, bad_template_idxs, axis=0)\n",
    "print(f\"{good_templates.shape[0]} good templates remaining.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53602f2f",
   "metadata": {},
   "source": [
    "### Take Channel Window and Localize Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd1bdbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 132/132 [00:01<00:00, 118.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Take the specified number of channels around the max channel\n",
    "templates_chans, templates_ptp_chans = take_channel_range(good_templates, n_channels_loc=n_channels)\n",
    "# Localize each template to a predicted position\n",
    "template_positions = localize_wfs(templates_ptp_chans, geom_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f8065",
   "metadata": {
    "id": "d04f8065"
   },
   "source": [
    "## Generate Synthetic Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "652d8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gamma distribution parameters for alpha position variable.\n",
    "a, loc, scale = 3, 100, 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0df5cdc",
   "metadata": {},
   "source": [
    "### Featurization Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbb19779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding noise to dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 80000/80000 [01:09<00:00, 1153.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving templates to folder /Users/johnzhou/research/spike-sorting/data/processed/featurization_train, array of shape: (80000, 20, 121)\n",
      "Saving predicted PTPs to folder /Users/johnzhou/research/spike-sorting/data/processed/featurization_train, array of shape: (80000, 20)\n",
      "Saving positions to folder /Users/johnzhou/research/spike-sorting/data/processed/featurization_train, array of shape: (80000, 4)\n",
      "Saving unit indices to folder /Users/johnzhou/research/spike-sorting/data/processed/featurization_train, array of shape: (80000,)\n",
      "Adding noise to dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 20000/20000 [00:10<00:00, 1849.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving templates to folder /Users/johnzhou/research/spike-sorting/data/processed/featurization_val, array of shape: (20000, 20, 121)\n",
      "Saving predicted PTPs to folder /Users/johnzhou/research/spike-sorting/data/processed/featurization_val, array of shape: (20000, 20)\n",
      "Saving positions to folder /Users/johnzhou/research/spike-sorting/data/processed/featurization_val, array of shape: (20000, 4)\n",
      "Saving unit indices to folder /Users/johnzhou/research/spike-sorting/data/processed/featurization_val, array of shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "featurize_train_experiment_name = \"featurization_train\"\n",
    "featurize_val_experiment_name = \"featurization_val\"\n",
    "\n",
    "train_frac = 0.8\n",
    "n_samples = 100000\n",
    "\n",
    "n_train_samples = round(n_samples * train_frac)\n",
    "n_val_samples = round(n_samples * (1 - train_frac))\n",
    "\n",
    "# Training data\n",
    "featurization_dataset(\n",
    "    templates_chans, template_positions, channel_positions, a, loc, scale, n_samples=n_train_samples, \n",
    "    raw_rec_path=raw_10s_path,\n",
    "    experiment_data_dir=PROCESS_DATA_DIR, \n",
    "    experiment_name=featurize_train_experiment_name\n",
    ")\n",
    "# Validation data\n",
    "featurization_dataset(\n",
    "    templates_chans, template_positions, channel_positions, a, loc, scale, n_samples=n_val_samples, \n",
    "    raw_rec_path=raw_10s_path, \n",
    "    experiment_data_dir=PROCESS_DATA_DIR, \n",
    "    experiment_name=featurize_val_experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11535b15",
   "metadata": {},
   "source": [
    "### Positional Invariance Analysis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31d0bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 1325.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving templates to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_x, array of shape: (100, 20, 121)\n",
      "Saving predicted PTPs to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_x, array of shape: (100, 20)\n",
      "Saving positions to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_x, array of shape: (100, 4)\n",
      "Saving unit indices to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_x, array of shape: (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 1461.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving templates to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_z, array of shape: (100, 20, 121)\n",
      "Saving predicted PTPs to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_z, array of shape: (100, 20)\n",
      "Saving positions to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_z, array of shape: (100, 4)\n",
      "Saving unit indices to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_z, array of shape: (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 1692.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving templates to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_y, array of shape: (100, 20, 121)\n",
      "Saving predicted PTPs to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_y, array of shape: (100, 20)\n",
      "Saving positions to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_y, array of shape: (100, 4)\n",
      "Saving unit indices to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_y, array of shape: (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 1484.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving templates to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_alpha, array of shape: (100, 20, 121)\n",
      "Saving predicted PTPs to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_alpha, array of shape: (100, 20)\n",
      "Saving positions to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_alpha, array of shape: (100, 4)\n",
      "Saving unit indices to folder /Users/johnzhou/research/spike-sorting/data/processed/invariance_analysis_alpha, array of shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "position_features = [\"x\", \"z\", \"y\", \"alpha\"]\n",
    "vary_samples = 100\n",
    "\n",
    "for vary_feature in position_features:\n",
    "    vary_experiment_name = \"invariance_analysis_{}\".format(vary_feature)\n",
    "    \n",
    "    positional_invariance_dataset(\n",
    "        templates_chans, template_positions, channel_positions, a, loc, scale, vary_feature=vary_feature, \n",
    "        n_samples=vary_samples, \n",
    "        experiment_data_dir=PROCESS_DATA_DIR, \n",
    "        experiment_name=vary_experiment_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b28d86",
   "metadata": {},
   "source": [
    "### Clustering Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d601c171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding noise to dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving templates to folder /Users/johnzhou/research/spike-sorting/data/processed/clusters_k=20, array of shape: (20000, 20, 121)\n",
      "Saving predicted PTPs to folder /Users/johnzhou/research/spike-sorting/data/processed/clusters_k=20, array of shape: (20000, 20)\n",
      "Saving positions to folder /Users/johnzhou/research/spike-sorting/data/processed/clusters_k=20, array of shape: (20000, 4)\n",
      "Saving unit indices to folder /Users/johnzhou/research/spike-sorting/data/processed/clusters_k=20, array of shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 20\n",
    "num_samples_per_cluster = 1000\n",
    "cluster_experiment_name = \"clusters_k={}\".format(num_clusters)\n",
    "\n",
    "clustering_dataset(templates_chans, template_positions, channel_positions, a, loc, scale, n_clusters=num_clusters, \n",
    "                   num_samples_per_cluster=num_samples_per_cluster, \n",
    "                   raw_rec_path=raw_10s_path,\n",
    "                   experiment_data_dir=PROCESS_DATA_DIR, \n",
    "                   experiment_name=cluster_experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd34eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
