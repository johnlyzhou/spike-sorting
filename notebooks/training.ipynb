{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "YNfB5_NjG0a6",
   "metadata": {
    "id": "YNfB5_NjG0a6"
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vdwfk_eZGrLZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdwfk_eZGrLZ",
    "outputId": "5b562a22-309a-4a21-c98d-ef17dfa29180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: omegaconf in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (2.1.1)\n",
      "Requirement already satisfied: pytorch_lightning in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (1.5.6)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from omegaconf) (4.8)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from omegaconf) (6.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from pytorch_lightning) (21.3)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from pytorch_lightning) (2021.11.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from pytorch_lightning) (4.0.1)\n",
      "Requirement already satisfied: torch>=1.7.* in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from pytorch_lightning) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from pytorch_lightning) (1.21.4)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from pytorch_lightning) (0.6.2)\n",
      "Requirement already satisfied: future>=0.17.1 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from pytorch_lightning) (0.18.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from pytorch_lightning) (2.7.0)\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from pytorch_lightning) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from pytorch_lightning) (4.62.3)\n",
      "Requirement already satisfied: aiohttp in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n",
      "Requirement already satisfied: requests in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.26.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from packaging>=17.0->pytorch_lightning) (3.0.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (58.0.4)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.19.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.43.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
      "Requirement already satisfied: six in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/johnzhou/anaconda3/envs/yass/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (5.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install omegaconf pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00589b45",
   "metadata": {
    "id": "00589b45"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'omegaconf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bf/yxvgch2n5pd2dn6nv_5msw9w0000gn/T/ipykernel_28122/260689082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0momegaconf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moperator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'omegaconf'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from operator import mul\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AafBHUAalMvY",
   "metadata": {
    "id": "AafBHUAalMvY"
   },
   "source": [
    "## Encoder/Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737b6bd",
   "metadata": {
    "id": "8737b6bd"
   },
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, conv_encoder_layers, use_batch_norm=False):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        for (out_channels, kernel, stride) in conv_encoder_layers:\n",
    "            layers.append(nn.Conv1d(in_channels, out_channels, kernel, stride=stride))\n",
    "            if use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(out_channels))\n",
    "            layers.append(nn.LeakyReLU(0.05))\n",
    "\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 encoder_output_dim,\n",
    "                 conv_decoder_layers,\n",
    "                 use_batch_norm=False):\n",
    "        \"\"\"1-D Convolutional Decoder\n",
    "\n",
    "        Args:\n",
    "            in_features (int): Number of input features\n",
    "            encoder_output_dim (list): Shape of the unflattened output from the encoder\n",
    "                (num_channels x ...)\n",
    "            conv_decoder_layers (list):List of tuples specifying ConvTranspose1d layers\n",
    "            use_batch_norm (bool, optional): Whether to add BatchNorm1d layers in \n",
    "                between ConvTranspose1d layers. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.Linear(in_features, reduce(mul, encoder_output_dim)),\n",
    "            nn.Unflatten(1, encoder_output_dim)\n",
    "        ]\n",
    "\n",
    "        in_channels = encoder_output_dim[0]\n",
    "        for i, (out_channels, kernel, stride, output_padding) in enumerate(conv_decoder_layers):\n",
    "            layers.append(\n",
    "                nn.ConvTranspose1d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel,\n",
    "                    stride=stride,\n",
    "                    output_padding=output_padding))\n",
    "            if use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(out_channels))\n",
    "            \n",
    "            # Don't add activation for last layer\n",
    "            if i != len(conv_decoder_layers) - 1:\n",
    "                layers.append(nn.LeakyReLU(0.05))\n",
    "\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, encoder, decoder, encoder_output_dim, encoding_dim):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        flattened_dim = reduce(mul, encoder_output_dim)\n",
    "        self.encoding = nn.Linear(flattened_dim, encoding_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        output = torch.flatten(self.encoder(x), start_dim=1)\n",
    "        return self.encoding(output)\n",
    "    \n",
    "    def decode(self, encoding):\n",
    "        return self.decoder(encoding)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aEz8ooDXlY2U",
   "metadata": {
    "id": "aEz8ooDXlY2U"
   },
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2yDq5jQ6lWbW",
   "metadata": {
    "id": "2yDq5jQ6lWbW"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder, encoder_output_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        flattened_dim = reduce(mul, encoder_output_dim)\n",
    "        self.latent_mean = nn.Linear(flattened_dim, latent_dim)\n",
    "        self.latent_log_var = nn.Linear(flattened_dim, latent_dim)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        output = torch.flatten(self.encoder(x), start_dim=1)\n",
    "        return self.latent_mean(output), self.latent_log_var(output)\n",
    "\n",
    "    def sample(self, mean, log_var):\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mean\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.encode(x)\n",
    "        z = self.sample(mean, log_var)\n",
    "        return mean, log_var, self.decode(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KXNJL9Ullfse",
   "metadata": {
    "id": "KXNJL9Ullfse"
   },
   "source": [
    "## SpikeSortingVAE LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d9550",
   "metadata": {
    "id": "df4d9550"
   },
   "outputs": [],
   "source": [
    "class SpikeSortingVAE(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.save_hyperparameters(config)\n",
    "        \n",
    "        model_config = config[\"model\"]\n",
    "        encoder = ConvEncoder(model_config[\"in_channels\"],\n",
    "                              model_config[\"conv_encoder_layers\"],\n",
    "                              use_batch_norm=model_config[\"use_batch_norm\"])\n",
    "        decoder = ConvDecoder(model_config[\"latent_dim\"], \n",
    "                              model_config[\"encoder_output_dim\"],\n",
    "                              model_config[\"conv_decoder_layers\"],\n",
    "                              use_batch_norm=model_config[\"use_batch_norm\"])\n",
    "        self.model = VAE(\n",
    "            encoder,\n",
    "            decoder,\n",
    "            model_config[\"encoder_output_dim\"],\n",
    "            model_config[\"latent_dim\"]\n",
    "        )\n",
    "        self.log_scale = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def prepare_data(self):\n",
    "        data_config = self.config[\"data\"]\n",
    "        templates = np.load(data_config[\"path\"])\n",
    "        x = torch.from_numpy(templates).float()\n",
    "        dataset = TensorDataset(x, x)\n",
    "        \n",
    "        total_samples = len(x)\n",
    "        n_train = int(data_config[\"train_val_split\"] * total_samples)\n",
    "        n_val = total_samples - n_train\n",
    "        self.train_dataset, self.val_dataset = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.config[\"data\"][\"train_batch_size\"])\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, batch_size=self.config[\"data\"][\"val_batch_size\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def gaussian_nll(self, x, x_hat):\n",
    "        scale = torch.exp(self.log_scale)\n",
    "        predicted_dist = torch.distributions.Normal(x_hat, scale)\n",
    "        batch_size = x.shape[0]\n",
    "        return -predicted_dist.log_prob(x).view(batch_size, -1).sum(dim=1)\n",
    "\n",
    "    def kl_divergence(self, mu, log_var):\n",
    "        return torch.mean(\n",
    "            0.5 * torch.sum(log_var.exp() - log_var + mu**2 - 1, dim=1), dim=0)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(\n",
    "            self.parameters(), lr=(self.config[\"learning_rate\"] or 1e-4))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        mean, log_var, x_hat = self.model(x)\n",
    "\n",
    "        reconstruction_loss = self.gaussian_nll(x, x_hat)\n",
    "        kl_divergence = self.kl_divergence(mean, log_var)\n",
    "        elbo = (reconstruction_loss + kl_divergence).mean()\n",
    "\n",
    "        self.log_dict({\n",
    "            'train_loss': elbo,\n",
    "            'train_recon_loss': reconstruction_loss.mean(),\n",
    "            'train_kld': kl_divergence.mean()\n",
    "        }, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return elbo\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        mean, log_var, x_hat = self.model(x)\n",
    "\n",
    "        reconstruction_loss = self.gaussian_nll(x, x_hat)\n",
    "        kl_divergence = self.kl_divergence(mean, log_var)\n",
    "        elbo = (reconstruction_loss + kl_divergence).mean()\n",
    "\n",
    "        self.log_dict({\n",
    "            'val_loss': elbo,\n",
    "            'val_recon_loss': reconstruction_loss.mean(),\n",
    "            'val_kld': kl_divergence.mean()\n",
    "        }, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return elbo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SvwrDmCzmCwF",
   "metadata": {
    "id": "SvwrDmCzmCwF"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e39bb",
   "metadata": {
    "id": "b25e39bb"
   },
   "outputs": [],
   "source": [
    "base_config = OmegaConf.create({\n",
    "    \"random_seed\": 4995,\n",
    "    \"model\": {\n",
    "        \"in_channels\": 20,\n",
    "        \"use_batch_norm\": True\n",
    "    },\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"data\": {\n",
    "        \"path\": \"templates.npy\",\n",
    "        \"train_val_split\": 0.8,\n",
    "        \"train_batch_size\": 100,\n",
    "        \"val_batch_size\": 100\n",
    "    },\n",
    "    \"trainer\": {\n",
    "        \"gpus\": 1,\n",
    "        \"max_epochs\": 60\n",
    "    }\n",
    "\n",
    "})\n",
    "\n",
    "two_conv_config = OmegaConf.create({\n",
    "    \"model\": {\n",
    "        \"conv_encoder_layers\": [[32, 5, 2], [16, 5, 2]],\n",
    "        \"conv_decoder_layers\": [[16, 5, 2, 0], [20, 5, 2, 0]],\n",
    "        \"encoder_output_dim\": [16, 28]\n",
    "    }\n",
    "})\n",
    "\n",
    "latent_dim_ablation_configs = [OmegaConf.merge(\n",
    "    base_config, two_conv_config, OmegaConf.create(c)) for c in [\n",
    "    {\n",
    "        \"name\": \"vae_2conv_12latent\",\n",
    "        \"model\": { \"latent_dim\": 12 }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"vae_2conv_10latent\",\n",
    "        \"model\": { \"latent_dim\": 10 }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"vae_2conv_8latent\",\n",
    "        \"model\": { \"latent_dim\": 8 }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"vae_2conv_6latent\",\n",
    "        \"model\": { \"latent_dim\": 6 }\n",
    "    }\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IyZkAtiknvvD",
   "metadata": {
    "id": "IyZkAtiknvvD"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce5a944",
   "metadata": {
    "id": "8ce5a944"
   },
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    seed_everything(config[\"random_seed\"])\n",
    "    system = SpikeSortingVAE(config)\n",
    "\n",
    "    experiment_name = config[\"name\"]\n",
    "    experiment_dir = Path(f\"./experiments/{experiment_name}\")\n",
    "    experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    tb_logger = TensorBoardLogger(\"experiments\", name=experiment_name)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=experiment_dir,\n",
    "        filename=\"{epoch}\",\n",
    "        auto_insert_metric_name=True\n",
    "    )\n",
    "\n",
    "    progress_bar_callback = TQDMProgressBar(refresh_rate=20)\n",
    "    trainer = Trainer(\n",
    "        **config[\"trainer\"],\n",
    "        callbacks=[checkpoint_callback, progress_bar_callback],\n",
    "        logger=tb_logger\n",
    "    )\n",
    "    trainer.fit(system)\n",
    "\n",
    "    train_templates, _ = system.train_dataset[:]\n",
    "    train_latent_reps, _, train_reconstructions = system(train_templates)\n",
    "    np.save(experiment_dir / \"train_latent_reps.npy\", train_latent_reps.detach().numpy())\n",
    "    np.save(experiment_dir / \"train_reconstructions.npy\", train_reconstructions.detach().numpy())\n",
    "\n",
    "    val_templates, _ = system.val_dataset[:]\n",
    "    val_latent_reps, _, val_reconstructions = system(val_templates)\n",
    "    np.save(experiment_dir / \"val_latent_reps.npy\", val_latent_reps.detach().numpy())\n",
    "    np.save(experiment_dir / \"val_reconstructions.npy\", val_reconstructions.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XBR4hK6fEI7w",
   "metadata": {
    "id": "XBR4hK6fEI7w"
   },
   "outputs": [],
   "source": [
    "for config in latent_dim_ablation_configs:\n",
    "    config = OmegaConf.to_container(config)\n",
    "    print(config[\"name\"])\n",
    "    print('-' * 50)\n",
    "    train(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RydyAxTk43bq",
   "metadata": {
    "id": "RydyAxTk43bq"
   },
   "source": [
    "## Latent Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J5NqAP7y491T",
   "metadata": {
    "id": "J5NqAP7y491T"
   },
   "outputs": [],
   "source": [
    "ldims_10 = SpikeSortingVAE.load_from_checkpoint(\"epoch=49.ckpt\")\n",
    "ldims_12 = SpikeSortingVAE.load_from_checkpoint(\"epoch=59.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aK_MKXPt5cm3",
   "metadata": {
    "id": "aK_MKXPt5cm3"
   },
   "outputs": [],
   "source": [
    "ldims_10.forward()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YNfB5_NjG0a6",
    "3PIyddIWoipn",
    "AafBHUAalMvY",
    "aEz8ooDXlY2U",
    "KXNJL9Ullfse"
   ],
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
